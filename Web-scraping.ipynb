{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web - scraping danych z platformy OLX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importowanie niezbędnich bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pobranie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie ofert dla miast Katowice na datę 01.12.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Liczba wszystkich ofert: 813\n",
      "Failed to fetch the page. Status code: 410\n",
      "\n",
      "Brak atrybutów dla oferty 447 (https://www.otodom.pl/pl/oferta/premium-bezposrednio-cicha-okolica-brynow-ID4nzLT.html)\n",
      "Failed to fetch the page. Status code: 410\n",
      "\n",
      "Brak atrybutów dla oferty 692 (https://www.otodom.pl/pl/oferta/4-pokojowe-mieszkanie-98m2-loggia-bez-prowizji-ID4g352.html)\n"
     ]
    }
   ],
   "source": [
    "# I. Pobranie ofert dla miasta Katowice na datę 01.12.2023\n",
    "\n",
    "# Na tym eatpie zostaną pobrane podstawowe infomacje na temat ofert takie jak:\n",
    "\n",
    "#       Nazwa oferty\n",
    "#       Lokalizacja\n",
    "#       Data dodania\n",
    "#       Powierzchnia\n",
    "#       Cena za m2\n",
    "#       Kwota (łączna)\n",
    "#       Zdjęcie\n",
    "#       Link\n",
    "\n",
    "def scrape_olx_page(url):\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        offers = []\n",
    "\n",
    "        for item in soup.select(\"div[data-cy='l-card']\"):\n",
    "            title_node = item.select_one(\"h6.css-16v5mdi.er34gjf0\")\n",
    "            location_date_node = item.select_one(\"p.css-veheph.er34gjf0\")\n",
    "            area_price_node = item.select_one(\"span.css-643j0o\")\n",
    "            total_price_node = item.select_one(\"p.css-10b0gli.er34gjf0\")\n",
    "            link_node = item.select_one(\"a.css-rc5s2u\")\n",
    "\n",
    "            title = title_node.text.strip() if title_node else None\n",
    "            total_price = total_price_node.text.strip() if total_price_node else None\n",
    "            link = urljoin(url, link_node['href']) if link_node else None\n",
    "\n",
    "            location_date_text = location_date_node.text.strip() if location_date_node else None\n",
    "            if location_date_text:\n",
    "                location, date_added = map(str.strip, location_date_text.rsplit('-', 1))\n",
    "            else:\n",
    "                location, date_added = None, None\n",
    "\n",
    "            area_price_text = area_price_node.text.strip() if area_price_node else None\n",
    "            if area_price_text:\n",
    "                area, price_per_m2 = map(str.strip, area_price_text.split('-', 1))\n",
    "            else:\n",
    "                area, price_per_m2 = None, None\n",
    "\n",
    "            offer = {\n",
    "                \"Nazwa oferty\": title,\n",
    "                \"Lokalizacja\": location,\n",
    "                \"Data dodania\": date_added,\n",
    "                \"Powierzchnia w m²\": area,\n",
    "                \"Cena za 1m²\": price_per_m2,\n",
    "                \"Kwota\": total_price,\n",
    "                \"Link\": link\n",
    "            }\n",
    "\n",
    "            offers.append(offer)\n",
    "\n",
    "        return offers\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch the page. Status code: {resp.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Nastepnie do głebszej analizy niezbedne jest pobranie również atrybutów bezpośrednio zawartych w danych ofercie. \n",
    "\n",
    "# Ze względu na to iż do Grupy OLX należy również serwis Otodom, na platformie OLX wyswietlają się oferty, które po kliknięci przenoszą nas bezpośrednio do strony Otodom, której struktura rózni się od stuktury strony OLX\n",
    "# W związku z tym, próba pobrania ofert, które znajdują się na stronie Oto - nie powiedziedzie się.Konieczne jest zdefiniowanie dwóch funkcji: \n",
    "#       Jedna - która będzie pobierała szczegóły oferty ze strony OLX\n",
    "#       Druga - która będzie pobierała szczegóły oferty ze strony OTODom \n",
    "\n",
    "# Na tym etapie załozóno również, ze aby móc porównywac oferty, których struktury się różnią, nalezy wybrac atrybuty unikalne dla oby rodzajów ofert.\n",
    "# W wyniku tej weryfikacji ustalono , że do analizy przechodzą cechy takie jak:\n",
    "#        Poziom (Piętro), \n",
    "#        Umeblowane (Czy mieskzanie jest umeblowane), \n",
    "#        Liczba pokoi oraz Opis oferty.\n",
    "# Dane te są popbierne już bezpośrednio z konkretnej oferty.\n",
    "\n",
    "\n",
    "\n",
    "def scrape_offer_details_olx(offer_url):\n",
    "    resp = requests.get(offer_url)\n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        attributes = soup.select(\"ul.css-sfcl1s li p.css-b5m1rv.er34gjf0\")\n",
    "        offer_attributes = {}\n",
    "\n",
    "        # Dodajemy kod do wydobycia opisu oferty\n",
    "        description_node = soup.select_one(\"div.css-1t507yq.er34gjf0\")\n",
    "        description = description_node.text.strip() if description_node else None\n",
    "        offer_attributes[\"Opis\"] = description\n",
    "\n",
    "        for attr in attributes:\n",
    "            parts = attr.text.split(\":\")\n",
    "            if len(parts) >= 2:\n",
    "                key = parts[0].strip()\n",
    "                value = parts[1].strip()\n",
    "                if key in [\"Poziom\", \"Umeblowane\", \"Liczba pokoi\"]:\n",
    "                    offer_attributes[key] = value\n",
    "\n",
    "        return offer_attributes\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch offer page. Status code: {resp.status_code}\")\n",
    "        return None\n",
    "\n",
    "def scrape_offer_details_otodom(offer_url):\n",
    "    resp = requests.get(offer_url, headers={\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    })\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        construction_status_node = soup.select_one(\"div[data-testid='table-value-construction_status']\")\n",
    "        rooms_num_node = soup.select_one(\"div[data-testid='table-value-rooms_num']\")\n",
    "        floor_node = soup.select_one(\"div[data-testid='table-value-floor']\")\n",
    "\n",
    "        construction_status = construction_status_node.text.strip() if construction_status_node else None\n",
    "        rooms_num = rooms_num_node.text.strip() if rooms_num_node else None\n",
    "        floor = floor_node.text.strip() if floor_node else None\n",
    "\n",
    "        description_node = soup.select_one(\"div.css-1wekrze.e1lbnp621\")\n",
    "        description = description_node.text.strip() if description_node else None\n",
    "\n",
    "        offer_attributes = {\n",
    "            \"Poziom\": floor,\n",
    "            \"Umeblowane\": construction_status,\n",
    "            \"Liczba pokoi\": rooms_num,\n",
    "            \"Opis\": description\n",
    "        }\n",
    "\n",
    "        return offer_attributes\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch the page. Status code: {resp.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "url_to_scrape_base = \"https://www.olx.pl/nieruchomosci/mieszkania/sprzedaz/katowice/q-mieszkanie/?page={}\"\n",
    "\n",
    "# Celem analizy jest zebranie wszystkich ofert dla miasta Katowice, natomiast na jednej stronie znajduje się zaledwie kilkadziesiąt ofert.\n",
    "# W związku z tym nalezy utworzyć olgorytm który będzie iterował, przez wszystkie dostępne strony na datę 01.12.2023  - 15 stron \n",
    "\n",
    "# 1. Iterowanie przez wszystkie strony i zebranie ofert\n",
    "\n",
    "total_offers = []\n",
    "\n",
    "for page_num in range(1, 16): \n",
    "    url_to_scrape = url_to_scrape_base.format(page_num)\n",
    "    total_offers += scrape_olx_page(url_to_scrape)\n",
    "\n",
    "print(f\"\\nLiczba wszystkich ofert: {len(total_offers)}\") # Sprawdzamy ile jest wszystkich ofert\n",
    "\n",
    "df_offers = pd.DataFrame(total_offers)\n",
    "\n",
    "# 2. Zebranie szczegółowych atrybutów dla ofert OLX oraz OTOdom\n",
    "\n",
    "all_attributes = []\n",
    "\n",
    "for index, row in df_offers.iterrows():\n",
    "    offer_url = row['Link']\n",
    "\n",
    "    if offer_url:\n",
    "        if \"otodom.pl\" in offer_url:\n",
    "            offer_attributes = scrape_offer_details_otodom(offer_url)\n",
    "            if offer_attributes:\n",
    "                all_attributes.append(offer_attributes)\n",
    "            else:\n",
    "                print(f\"\\nBrak atrybutów dla oferty {index + 1} ({offer_url})\")\n",
    "        else:\n",
    "            offer_attributes = scrape_offer_details_olx(offer_url)\n",
    "            if offer_attributes:\n",
    "                all_attributes.append(offer_attributes)\n",
    "            else:\n",
    "                print(f\"\\nBrak atrybutów dla oferty {index + 1} ({offer_url})\")\n",
    "    else:\n",
    "        print(f\"\\nBrak adresu URL dla oferty {index + 1}\")\n",
    "\n",
    "# Tworzenie DataFrame z atrybutów\n",
    "df_attributes = pd.DataFrame(all_attributes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapisanie danych do plików CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Połącznie danych na temat ofert oraz szczegółowych atrybutów\n",
    "merged_df = pd.concat([df_offers, df_attributes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liczba_ofert_z_liczba_pokoi_1 = len(merged_df[merged_df['Liczba pokoi'] == '1'])\n",
    "liczba_ofert_z_liczba_pokoi_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_df_13g.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
